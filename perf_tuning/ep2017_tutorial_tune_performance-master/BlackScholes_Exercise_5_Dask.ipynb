{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Black Scholes Exercise 5: Dask implementation - data parallelism\n",
    "#### Dask pickles data to transfer across nodes\n",
    "\n",
    "- Use cProfile and Line Profiler to look for bottlenecks and hotspots in the code, then use the diagnostic part of dask to look for help"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Boilerplate for the example\n",
    "\n",
    "import cProfile\n",
    "import pstats\n",
    "import numpy as np\n",
    "%load_ext line_profiler\n",
    "\n",
    "import dask\n",
    "import dask.array as da\n",
    "\n",
    "from dask.array import log, sqrt, exp\n",
    "from numpy import erf, invsqrt\n",
    "# ------------------------------------\n",
    "try:\n",
    "    import numpy.random_intel as rnd\n",
    "except:\n",
    "    import numpy.random as rnd\n",
    "\n",
    "# make xrange available in python 3\n",
    "try:\n",
    "    xrange\n",
    "except NameError:\n",
    "    xrange = range\n",
    "\n",
    "SEED = 7777777\n",
    "S0L = 10.0\n",
    "S0H = 50.0\n",
    "XL = 10.0\n",
    "XH = 50.0\n",
    "TL = 1.0\n",
    "TH = 2.0\n",
    "RISK_FREE = 0.1\n",
    "VOLATILITY = 0.2\n",
    "# RISK_FREE = np.float32(0.1)\n",
    "# VOLATILITY = np.float32(0.2)\n",
    "# C10 = np.float32(1.)\n",
    "# C05 = np.float32(.5)\n",
    "# C025 = np.float32(.25)\n",
    "TEST_ARRAY_LENGTH = 1024\n",
    "\n",
    "###############################################\n",
    "\n",
    "def gen_data(nopt):\n",
    "    return (\n",
    "        rnd.uniform(S0L, S0H, nopt),\n",
    "        rnd.uniform(XL, XH, nopt),\n",
    "        rnd.uniform(TL, TH, nopt),\n",
    "        )\n",
    "\n",
    "nopt=100000\n",
    "chunk=2000\n",
    "price, strike, t = gen_data(nopt)\n",
    "price = da.from_array(price, chunks=(chunk,), name=False)\n",
    "strike = da.from_array(strike, chunks=(chunk,), name=False)\n",
    "t = da.from_array(t, chunks=(chunk,), name=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Dask Black Scholes algorithm - multi-process method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A lot of things will happen with Dask, and you will see this in cProfile, such as starting async torando, which comes with an overhead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def black_scholes ( nopt, price, strike, t, rate, vol):\n",
    "    mr = -rate\n",
    "    sig_sig_two = vol * vol * 2\n",
    "\n",
    "    P = price\n",
    "    S = strike\n",
    "    T = t\n",
    "\n",
    "    a = log(P / S)\n",
    "    b = T * mr\n",
    "\n",
    "    z = T * sig_sig_two\n",
    "    c = 0.25 * z\n",
    "    y = da.map_blocks(invsqrt, z)\n",
    "\n",
    "    w1 = (a - b + c) * y\n",
    "    w2 = (a - b - c) * y\n",
    "\n",
    "    d1 = 0.5 + 0.5 * da.map_blocks(erf, w1)\n",
    "    d2 = 0.5 + 0.5 * da.map_blocks(erf, w2)\n",
    "\n",
    "    Se = exp(b) * S\n",
    "\n",
    "    call = P * d1 - Se * d2\n",
    "    put = call - P + Se\n",
    "    \n",
    "    return da.compute( da.stack((put, call)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now run timeit, cProfile, and line_profiler\n",
    "\n",
    "What do you notice in the profile info?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now let's start the Local Cluster instead - distributed context\n",
    "\n",
    "Watch how the distributed mode changes things"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from dask.distributed import Client\n",
    "client = Client()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Go to http://localhost:8787/status"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dask calling NumPy\n",
    "\n",
    "Where are the NumPy differences?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'erf'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-8bf8893ad111>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlog\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minvsqrt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mblack_scholes_numpy_mod\u001b[0m \u001b[0;34m(\u001b[0m \u001b[0mnopt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstrike\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvol\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mmr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mrate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0msig_sig_two\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvol\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mvol\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'erf'"
     ]
    }
   ],
   "source": [
    "from numpy import log, exp, erf, invsqrt\n",
    "\n",
    "def black_scholes_numpy_mod ( nopt, price, strike, t, rate, vol ):\n",
    "    mr = -rate\n",
    "    sig_sig_two = vol * vol * 2\n",
    "\n",
    "    P = price\n",
    "    S = strike\n",
    "    T = t\n",
    "\n",
    "    a = log(P / S)\n",
    "    b = T * mr\n",
    "\n",
    "    z = T * sig_sig_two\n",
    "    c = 0.25 * z\n",
    "    y = invsqrt(z)\n",
    "\n",
    "    w1 = (a - b + c) * y\n",
    "    w2 = (a - b - c) * y\n",
    "\n",
    "    d1 = 0.5 + 0.5 * erf(w1)\n",
    "    d2 = 0.5 + 0.5 * erf(w2)\n",
    "\n",
    "    Se = exp(b) * S\n",
    "\n",
    "    call = P * d1 - Se * d2\n",
    "    put = call - P + Se\n",
    "    \n",
    "    return np.stack((call, put))\n",
    "\n",
    "\n",
    "def black_scholes_dask ( nopt, price, strike, t, rate, vol, schd=None ):\n",
    "    return da.map_blocks( black_scholes_numpy_mod, nopt, price, strike, t, rate, vol, new_axis=0 ).compute(get = schd)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now run timeit, cProfile, and line_profiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
